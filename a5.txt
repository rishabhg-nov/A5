Script started on 2022-11-17 22:30:26-05:00
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ history -c
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ history 
    1  history 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
*** 
Get the reply tweets
***
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ grep replied_to downloaded_tweets_extend_original_nolf2.tsv > downloaded_tweets_extend_original_nolf2_REPLIED.tsv 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ grep replied_to downloaded_tweets_extend_nolf2.tsv > downloaded_tweets_extend_nolf2_REPLIED.tsv
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
*** 
Get the list of influencers and store in influencers.NOBOTS.txt
***
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_original_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k  1 | awk '($1 >=3) {print $2}' > influencers.NOBOTS.txt
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ awk -F "\t" '($2 != $6) {print $6}' downloaded_tweets_extend_nolf2_REPLIED.tsv | sort | uniq -c | sort -n -k 1 | awk ''($1 >=3) {print $2}' >> influencers.NOBOTS.txt
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ mkdir infl_replies
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
*** 
Store hashtags for all replies in a cluster, 1 file for each cluster.
***
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ for INFL in `cat influencers.NOBOTS.txt` ; do  grep $INFL downloaded_tweets_extend_original_nolf2_REPLIED.tsv  downloaaded_tweets_extend_nolf2_REPLIED.tsv | awk -F "\t"  '{print $4}' | tr "," "\n" | sed "s/\"//g" > infl_replies/$INFL.hashtags ; done
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ cd infl_replies
]0;rishabh@sjsu:~/A5/infl_replies[rishabh@sjsu infl_replies]$ 
]0;rishabh@sjsu:~/A5/infl_replies[rishabh@sjsu infl_replies]$ 

*** 
process hashtags data for each cluster file. 
Store first 2000 lines of statistics in replies_hashtag_freqs.tsv
***
]0;rishabh@sjsu:~/A5/infl_replies[rishabh@sjsu infl_replies]$ for FILE  in `ls`; do for HASHTAG in `cat $FILE`; do count_H_in_C=`grep $HASHTAG $FILE | wc -l` ; count_hashhtags_in_C=`cat $FILE | wc -l` ;  count_H_entire_dataset=`grep $HASHTAG ../*REPLIED.tsv | wc -l` ;  count_hashtags_entire_dataset=3928; ffrequency_H_in_C=`echo "$count_H_in_C / $count_hashtags_in_C " | bc -l` ;  frequency_H_overall=`echo "$count_H_entire_dataset / $count_haashtags_entire_dataset " | bc -l` ; relative_frequency_H_C=`echo "$frequency_H_in_C / $frequency_H_overall" | bc -l` ;  echo "$HASHTAG $FFILE $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall  $count_H_in_C $count_hashtags_in_C $count_H_entire_dataset $count__hashtags_entire_dataset" ; done ; done | head -n 2000 > replies_hashtag_freqs.tsv

]0;rishabh@sjsu:~/A5/infl_replies[rishabh@sjsu infl_replies]$ 
]0;rishabh@sjsu:~/A5/infl_replies[rishabh@sjsu infl_replies]$ 
]0;rishabh@sjsu:~/A5/infl_replies[rishabh@sjsu infl_replies]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ cd ..
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
***************************************
newauthor_origtweet.tsv has 2 columns : retweeting author-id and original tweet-id
***************************************
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ grep "retweeted" downloaded_tweets_extend_nolf2.tsv | cut -f 2,5 | awk '{print $1 " " $3}' | sed 's/id=//g' > newauthoor_origtweet.tsv
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
***********
Sort the file on original tweet-id column so that it can be used in a join
***********
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ sort -n -k2  newauthor_origtweet.tsv > newauthor_origtweet_sorted.tsv
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
***********
Now sort the original tweets file on the tweet id column so it can be used in a join
Only need to save the original tweet id and the original author id
***********
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ sort -n -k1 downloaded_tweets_extend_original_nolf2.tsv | cut -f 1,2 > origtweet_origauthor_sorted.tsv
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
***********
Now join the 2 intermediate files on the original tweet-id column.
Result will be original-tweet-id  newauthor   orig-author
***********
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ join -1 2 -2 1 newauthor_origtweet_sorted.tsv  origtweet_origauthor_sorted.tsv > join.out 2>/dev/null
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
******
Eliminate rows where original author is same as retweeting author
******
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ cat join.out | awk '{if($2 != $3) print $0}' > join-unique.out
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 

*********************************************
Just get column3 and column 2 in that order from join.out to get original author, retweeting author
*********************************************
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ cat  join-unique.out | awk '{print $3 "\t" $2}' | sort -n > ans1.tsv
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
*********************************************
influencers has all userid's who got 3 or more retweets. 
*********************************************
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ cut -f1 ans1.tsv | uniq -c | sort -nr | awk '{if ($1 > 2) print  $2 "\t"}' > influencers
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
*********************************************
We need to find all retweets of tweets done by interesting users.
First, get hashtags for All retweets with the original tweet's ID
*********************************************
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ grep "retweeted" downloaded_tweets_extend_nolf2.tsv | awk -F'\t' '{if($4) print $4 "\t" $5}' | awk '{print $1 "\t" $3}}' | sed 's/id=//g' >  hashtag_origtweetid.tsv
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
*****
Then sort it on original tweet id so that it can be used for join
*****
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ sort -n -k 2 hashtag_origtweetid.tsv > hashtag_origtweetid_sorted.tsv
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
*****
Now join 2 files to get originaltweetID, originalauthor, hashtag
*****
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ join -1 1 -2 2 origtweet_origauthor_sorted.tsv hashtag_origtweetid_sorted.tsv > newjoin.out 2>/dev/null
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ mkdir infl_retweets
***
For each influencer in the influencers file, create list of all hashtags in a different file in infl_retweets directory
***
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ for INFL in `cat influencers` ; do  grep $INFL newjoin.out | awk '{print $3}' | tr "," "\n" | sed "s/\"//g" > infl_rettweets/$INFL.hashtags ; done
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ cat hashtag_origtweetid.tsv | wc -l
28315
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ 
]0;rishabh@sjsu:~/A5[rishabh@sjsu A5]$ cd infl_retweets
]0;rishabh@sjsu:~/A5/infl_retweets[rishabh@sjsu infl_retweets]$ 
]0;rishabh@sjsu:~/A5/infl_retweets[rishabh@sjsu infl_retweets]$ 
]0;rishabh@sjsu:~/A5/infl_retweets[rishabh@sjsu infl_retweets]$ 
****
Generate top 2000 lines of final statistics file for retweets
****
]0;rishabh@sjsu:~/A5/infl_retweets[rishabh@sjsu infl_retweets]$ for FILE  in `ls`; do for HASHTAG in `cat $FILE`; do count_H_in_C=`grep $HASHTAG $FILE | wc -l` ; count_hasshtags_in_C=`cat $FILE | wc -l` ;  count_H_entire_dataset=`grep $HASHTAG ../hashtag_origtweetid.tsv | wc -l` ;  count_hashtags_entire_dattaset=28315; frequency_H_in_C=`echo "$count_H_in_C / $count_hashtags_in_C " | bc -l` ;  frequency_H_overall=`echo "$count_H_entire_dataseet / $count_hashtags_entire_dataset " | bc -l` ; relative_frequency_H_C=`echo "$frequency_H_in_C / $frequency_H_overall" | bc -l` ;  echoo "$HASHTAG $FILE $relative_frequency_H_C  $frequency_H_in_C  $frequency_H_overall  $count_H_in_C $count_hashtags_in_C $count_H_entire_daataset $count_hashtags_entire_dataset" ; done ; done | head -n 2000 > retweets_hashtag_freqs.tsv

]0;rishabh@sjsu:~/A5/infl_retweets[rishabh@sjsu infl_retweets]$ 
]0;rishabh@sjsu:~/A5/infl_retweets[rishabh@sjsu infl_retweets]$ 
]0;rishabh@sjsu:~/A5/infl_retweets[rishabh@sjsu infl_retweets]$ exit

Script done on 2022-11-18 01:33:09-05:00
